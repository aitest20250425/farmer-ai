#å€å¡Šä¸€
import torch
from torchvision import models, transforms
print(torch.__version__)
#å€å¡ŠäºŒ
import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from torchvision import models, transforms
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
#å€å¡Šä¸‰
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

data_root = 'data'
batch_size = 32

# å®šç¾©è½‰æ›
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ResNet è¼¸å…¥éœ€è¦ 224x224
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ResNeté è¨“ç·´æ¨¡åž‹çš„å¹³å‡å€¼
                         std=[0.229, 0.224, 0.225])
])

# ä½¿ç”¨ ImageFolder ç›´æŽ¥è®€è³‡æ–™å¤¾
train_dataset = datasets.ImageFolder(os.path.join(data_root, 'train'), transform=transform)
val_dataset = datasets.ImageFolder(os.path.join(data_root, 'val'), transform=transform)
test_dataset = datasets.ImageFolder(os.path.join(data_root, 'test'), transform=transform)

# å»ºç«‹ DataLoader
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size)
test_loader = DataLoader(test_dataset, batch_size=batch_size)

#å€å¡Šå››
from PIL import Image
import numpy as np
import os

# é¡žåˆ¥åç¨±åˆ°æ•¸å­—æ¨™ç±¤çš„å°æ‡‰ï¼ˆä¾ä½ è³‡æ–™å¤¾çµæ§‹èª¿æ•´ï¼‰
class_names = [
    'Bacterial leaf blight of rice',
    'Bakanae disease',
    'Brown spot',
    'healthy',
    'Rhizoctonia blight',
    'Rice blast',
    'Sheath blight',
    'white-tup nematode'
]
class_to_idx = {name: i for i, name in enumerate(class_names)}

def load_dataset(base_path, augment=False):
    imgs = []
    labels = []
    print(f"ðŸš€ è¼‰å…¥è³‡æ–™é›†ï¼š{base_path}")
    for class_name in os.listdir(base_path):
        class_path = os.path.join(base_path, class_name)
        print(f"ðŸ” è™•ç†é¡žåˆ¥ï¼š{class_name}")
        if not os.path.isdir(class_path):
            continue
        label = class_to_idx.get(class_name)
        if label is None:
            print(f"âš ï¸ é¡žåˆ¥ '{class_name}' æ²’æœ‰å°æ‡‰æ¨™ç±¤ï¼Œç•¥éŽ")
            continue
        for file in os.listdir(class_path):
            path = os.path.join(class_path, file)
            try:
                img = Image.open(path).convert('RGB')
                img = img.resize((224, 224))
                img_array = np.array(img)
                imgs.append(img_array)
                labels.append(label)
            except Exception as e:
                print(f"âŒ åœ–ç‰‡è®€å–å¤±æ•—ï¼š{path}ï¼ŒéŒ¯èª¤ï¼š{e}")
    print(f"âœ… è¼‰å…¥å®Œæˆï¼Œå…± {len(imgs)} å¼µåœ–ç‰‡")
    return np.array(imgs), np.array(labels)


#å€å¡Šäº”
train_img, train_label = load_dataset('data/train', augment=True)
val_img, val_label = load_dataset('data/val')
test_img, test_label = load_dataset('data/test')

#å€å¡Šå…­
# è£ç½®è¨­å®š
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


#å€å¡Šä¸ƒ
# åœ–åƒç¶­åº¦æª¢æŸ¥
print("train_img shape:", train_img.shape)
print("val_img shape:", val_img.shape)
print("test_img shape:", test_img.shape)
if train_img.ndim != 4 or val_img.ndim != 4 or test_img.ndim != 4:
    raise ValueError("åœ–åƒè³‡æ–™æ ¼å¼éŒ¯èª¤ï¼ŒæœŸæœ›ç‚º(N, 224, 224, 3)")

#å€å¡Šå…«
#  åœ–â½šè½‰ç‚ºPyTorch tensor ä¸¦è½‰æ›ç¶­åº¦ï¼Œä¸¦æ­£è¦åŒ–â¾„[0, 1]
train_img = torch.tensor(train_img / 255.0, dtype=torch.float32).permute(0, 3, 1, 2)
val_img = torch.tensor(val_img / 255.0, dtype=torch.float32).permute(0, 3, 1, 2)
test_img = torch.tensor(test_img / 255.0, dtype=torch.float32).permute(0, 3, 1, 2)
train_label = torch.tensor(train_label, dtype=torch.long)
val_label = torch.tensor(val_label, dtype=torch.long)
test_label = torch.tensor(test_label, dtype=torch.long)

#å€å¡Šä¹
train_img_tensor = torch.tensor(train_img / 255.0, dtype=torch.float32).permute(0, 3, 1, 2)
val_img_tensor = torch.tensor(val_img / 255.0, dtype=torch.float32).permute(0, 3, 1, 2)
test_img_tensor = torch.tensor(test_img / 255.0, dtype=torch.float32).permute(0, 3, 1, 2)
print("train_img_tensor shape:", train_img_tensor.shape)
print("val_img_tensor shape:", val_img_tensor.shape)
print("test_img_tensor shape:", test_img_tensor.shape)
train_loader = DataLoader(TensorDataset(train_img_tensor, train_label), batch_size=batch_size, shuffle=True)
val_loader = DataLoader(TensorDataset(val_img_tensor, val_label), batch_size=batch_size)
test_loader = DataLoader(TensorDataset(test_img_tensor, test_label), batch_size=batch_size)


#å€å¡Šå
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
from torch.optim.lr_scheduler import ReduceLROnPlateau

# æª¢æŸ¥è¨­å‚™
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("ä½¿ç”¨è¨­å‚™:", device)

# è¨­å®šè³‡æ–™ç›®éŒ„èˆ‡è¶…åƒæ•¸
data_root = 'data'
batch_size = 32
num_epochs = 20
num_classes = 8  # åˆ†æˆ 8 é¡ž

# å®šç¾©è³‡æ–™è½‰æ›
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],  # ImageNet çš„ mean
                         [0.229, 0.224, 0.225])  # ImageNet çš„ std
])

# è¼‰å…¥è³‡æ–™é›†
train_dataset = datasets.ImageFolder(os.path.join(data_root, 'train'), transform=transform)
val_dataset = datasets.ImageFolder(os.path.join(data_root, 'val'), transform=transform)
test_dataset = datasets.ImageFolder(os.path.join(data_root, 'test'), transform=transform)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size)
test_loader = DataLoader(test_dataset, batch_size=batch_size)

# å»ºç«‹æ¨¡åž‹
model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)

# æå¤±å‡½æ•¸èˆ‡å„ªåŒ–å™¨
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)

# è¨“ç·´æ¨¡åž‹
best_acc = 0.0
train_losses, val_losses = [], []
train_accuracies, val_accuracies = [], []

for epoch in range(num_epochs):
    model.train()
    train_loss, correct, total = 0.0, 0, 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    train_acc = 100 * correct / total
    avg_train_loss = train_loss / len(train_loader)

    # é©—è­‰
    model.eval()
    val_loss, val_correct, val_total = 0.0, 0, 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    val_acc = 100 * val_correct / val_total
    avg_val_loss = val_loss / len(val_loader)

    train_losses.append(avg_train_loss)
    val_losses.append(avg_val_loss)
    train_accuracies.append(train_acc)
    val_accuracies.append(val_acc)

    print(f"Epoch [{epoch+1}/{num_epochs}] "
          f"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%, "
          f"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%")

    scheduler.step(avg_val_loss)

    # å„²å­˜æœ€ä½³æ¨¡åž‹
    if val_acc > best_acc:
        best_acc = val_acc
        torch.save(model.state_dict(), "best_resnet50.pth")
        print("ðŸ”½ å„²å­˜æœ€ä½³æ¨¡åž‹ (val acc: {:.2f}%)".format(val_acc))
